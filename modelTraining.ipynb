{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f092a5b-c524-4567-b648-52109ad4c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pacmap\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "import sentencepiece as spm\n",
    "from IPython.display import clear_output\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from termcolor import colored, cprint\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pacmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911209e0-6108-47bc-930b-731af5c1182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NAME=\"200k_dict\"\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=500\n",
    "\n",
    "path = \"./out\" + TEST_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ebe25-34ba-4454-9927-a23787459da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(typ, obj):\n",
    "    with open('./data/' +  TEST_NAME + \"_\" + typ + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "        \n",
    "def loadData(typ):\n",
    "    ret = None\n",
    "    with open('./data/' +  TEST_NAME + \"_\" + typ + '.pkl', 'rb') as f:\n",
    "        ret = pickle.load(f)\n",
    "    assert ret is not None\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7facdf36-8348-4fd0-a6f4-5f82abfcbce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = loadData(\"training\")  # numeric, weights, data, labels\n",
    "inSize = len(d[\"numeric\"][0])\n",
    "outSize = len(d[\"weights\"][0])\n",
    "print(f\"Samples: {len(d['numeric'])}, Input Size: {inSize}, Output Size: {outSize}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bdb897-6410-4d06-84c9-4f7e161c7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPac(corpus, maxNum=-1, colors = ['blue', 'orange'], names=['Nominal','Crash'], sz=1.5, alpha=0.5):\n",
    "    if maxNum < 0:\n",
    "        maxNum = len(corpus)\n",
    "    embedding = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0) \n",
    "    xt = embedding.fit_transform(corpus[:maxNum], init=\"pca\")\n",
    "    cmap = mpl.colors.ListedColormap(colors)\n",
    "    sns.set_style('darkgrid')\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    ax.scatter(xt[:, 0], xt[:, 1], s=sz, alpha=alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c5ac2-c2f6-4ff5-9767-c41ba2fc8c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "672764ca-0162-44a8-bbe0-b822886368a5",
   "metadata": {},
   "source": [
    "inputs = layers.Input(shape=(inSize,))\n",
    "x = layers.Dense(85, activation=\"relu\", name=\"dense1\")(inputs) # 85\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(200, activation=\"relu\", name=\"dense2\")(x) #100\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "outputs = layers.Dense(outSize)(x)\n",
    "modelDense = keras.Model(inputs=inputs, outputs=outputs)\n",
    "modelDense.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    "modelDense.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb3a7174-2f63-4ef5-b046-b58fc795ba5e",
   "metadata": {},
   "source": [
    "MODEL_FILE_DENSE=\"./data/\" + TEST_NAME + \"_dense.hdf5\"\n",
    "modelSaveDense = ModelCheckpoint(MODEL_FILE_DENSE, save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe460cdf-e937-4d03-aedf-658804db008d",
   "metadata": {},
   "source": [
    "\n",
    "history = modelDense.fit(d['numeric'], d['weights'],\n",
    "      batch_size=BATCH_SIZE,\n",
    "      epochs=EPOCHS,\n",
    "      validation_split=0.15,\n",
    "      verbose=0,\n",
    "      callbacks=[modelSaveDense])\n",
    "saveData(\"denseHistory\", history.history)\n",
    "plotHistory(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7a762-2b27-4fec-af55-27e27a8d650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        \n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        print(inputs)\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        #ffn_output = self.ffn(inputs + attn_output)\n",
    "        \n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "        #return (ffn_output)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'ff_dim': self.ff_dim,\n",
    "            'rate': self.rate,\n",
    "            'att': self.att,\n",
    "            'ffn': self.ffn\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5caffe5-62b8-44e8-b67d-0aecebc8126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim, **kwargs):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'maxlen': self.maxlen,\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'token_emb': self.token_emb,\n",
    "            'pos_emb': self.pos_emb\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        print(config)\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db5f02-0661-44b1-9a70-ddb1b9841338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizLayer(m, x_test):\n",
    "  viz = m.predict(x_test)\n",
    "  vizp = np.reshape(viz, (viz.shape[0],viz.shape[1]*viz.shape[2]))\n",
    "  vp, lp = shuffle(vizp, list(range(len(vizp))))\n",
    "  plotPac(vp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ec007-8388-4fd7-a2cd-5d772a595a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED = 32\n",
    "NUM_HEADS = 8\n",
    "FF_DIM = 32\n",
    "\n",
    "LARGE_MODEL = False\n",
    "\n",
    "if LARGE_MODEL:\n",
    "    EMBED = 128\n",
    "    NUM_HEADS = 32\n",
    "    FF_DIM = 128\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6cb3e-53fc-4a54-a28c-7338a98a3127",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = EMBED #32 # 128# Embedding size for each token\n",
    "num_heads =  NUM_HEADS #8 #12  # Number of attention heads\n",
    "ff_dim = FF_DIM #32 #128  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(inSize,))\n",
    "print(inputs)\n",
    "embedding_layer = TokenAndPositionEmbedding(inSize, inSize, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "print(x)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "if LARGE_MODEL:\n",
    "    x = layers.Dense(FF_DIM, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(outSize)(x)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e64d5-5ad1-4b91-8efc-5174a6f74a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "#model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "MODEL_FILE_TRANSFORMER=\"./data/\" + TEST_NAME + \"_transformer.hdf5\"\n",
    "modelSaveTransformer = ModelCheckpoint(MODEL_FILE_TRANSFORMER, save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b9852a-5137-43f9-bed0-0d100ad835ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305c894-b4a0-4db7-ad1e-7a4c291b534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = shuffle(d[\"numeric\"], d[\"weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8084913-3435-4080-829f-fff3364f3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33458a26-9d56-4652-9358-d5419ea15b5f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(trainX, trainY,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          callbacks=[modelSaveTransformer, earlyStop],\n",
    "          validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e371284-6a52-44ae-b7ab-fb6e9229776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistory(history_dict):\n",
    "    loss_values = history_dict[\"loss\"]\n",
    "    val_loss_values = history_dict[\"val_loss\"]\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "    plt.figure(figsize=(10, 4), dpi=100)\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.suptitle(\"Transformer Model Training\")\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "\n",
    "    plt.plot(epochs, loss_values, \"b\", label=\"Training Loss\")\n",
    "    plt.plot(epochs, val_loss_values, \"orange\", label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    #plt.savefig(\"loss.png\")\n",
    "    #plt.show()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    acc_values = history_dict[\"mae\"]\n",
    "    val_acc_values = history_dict[\"val_mae\"]\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "    #plt.figure(figsize=(5, 3), dpi=100)\n",
    "\n",
    "    plt.plot(epochs, acc_values, \"b\", label=\"Training Error\")\n",
    "    plt.plot(epochs, val_acc_values, \"orange\", label=\"Mean Absolute Error\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"lossAccuracy.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1203b01-939e-4591-87e8-d61eefb030f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saveData(\"transformerHistory\", history.history)\n",
    "plotHistory(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5c699-4228-4250-a254-d8b8785e5b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedOnly_model = keras.Model(model.inputs,[model.layers[1].output])\n",
    "transformerOnly_model = keras.Model(model.inputs, model.layers[2].output)\n",
    "\n",
    "#transformerOnly_model = keras.Model(model.inputs, model.get_layer(\"transformer_block_1\").output)\n",
    "transformerOnly_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169c448-b51d-42b2-8f5b-4d1c4d9ca85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vizLayer(embedOnly_model, d[\"numeric\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c072d-fccb-4563-afef-309c7e517976",
   "metadata": {},
   "outputs": [],
   "source": [
    "vizLayer(transformerOnly_model, d[\"numeric\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4eed2-40e1-4893-aa38-0c83d506a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = keras.models.load_model(MODEL_FILE_TRANSFORMER\n",
    "     , custom_objects={\"TokenAndPositionEmbedding\": TokenAndPositionEmbedding\n",
    "     , \"TransformerBlock\": TransformerBlock})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53141aaf-2757-4a39-b2d9-a7497b5bc96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.evaluate(d[\"numeric\"], d[\"weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a2ff8-f840-4a04-b505-3211917b72dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-3.9",
   "language": "python",
   "name": "tf-3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
